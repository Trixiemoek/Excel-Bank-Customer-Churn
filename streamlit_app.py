# -*- coding: utf-8 -*-
"""streamlit_app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HezOaSkEhs5kepRz57UJHmBGYrRuJbfg
"""
import subprocess

# Check if joblib is installed, if not, install it
try:
    import joblib
except ImportError:
    subprocess.check_call(['pip', 'install', 'joblib'])
import streamlit as st
import pandas as pd
import joblib
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score
from sklearn.metrics import classification_report

# Load the trained model
model = joblib.load('best_model.pkl')

# Define the Streamlit app
def main():
    st.title('Customer Churn Prediction using Machine Learning')

    # File upload section
    st.sidebar.header('Upload CSV File')
    uploaded_file = st.sidebar.file_uploader("Choose a CSV file", type="csv")

    if uploaded_file is not None:
        # Read the uploaded CSV file
        data = pd.read_csv(uploaded_file)

        # Display the uploaded data
        st.subheader('Uploaded Data:')
        st.write(data)

        # Make predictions
        predictions = model.predict(data)

        # Display predictions
        st.subheader('Predictions:')
        st.write(predictions)

        # Evaluate the model on the uploaded data
        st.subheader('Evaluation Metrics:')
        # Assuming X_test and y_test are your test features and labels
        y_pred = model.predict(data)
        # You may need to preprocess the data before evaluating
        # Calculate evaluation metrics
        # Assuming y_test is the true labels
        # If you have them, you can calculate the evaluation metrics
        # accuracy = accuracy_score(y_test, y_pred)
        # recall = recall_score(y_test, y_pred)
        # precision = precision_score(y_test, y_pred)
        # f1 = f1_score(y_test, y_pred)
        # Print evaluation metrics
        # st.write("Accuracy:", accuracy)
        # st.write("Recall:", recall)
        # st.write("Precision:", precision)
        # st.write("F1 Score:", f1)

        # Classification report
        # st.subheader("Classification Report:")
        # st.write(classification_report(y_test, y_pred))

        # Get feature importances from the model
        if hasattr(model, 'feature_importances_'):
            feature_importance = model.feature_importances_
            # Assuming your features are stored in data
            feature_names = data.columns.tolist()
            # Create a DataFrame to associate feature names with their importances
            feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})
            # Sort the DataFrame by importance in descending order
            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)
            # Display feature importances
            st.subheader('Feature Importances:')
            st.write(feature_importance_df)

if __name__ == '__main__':
    main()

